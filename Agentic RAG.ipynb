{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77df5c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI,GoogleGenerativeAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, MessagesState,START,END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import Annotated, Literal,TypedDict, List\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "327f8cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I am! I'm ready to help you with whatever you need.\n",
      "\n",
      "Please tell me how I can assist you.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        temperature=0)\n",
    "    response = llm.invoke(\"Are you ready to help me\")\n",
    "    print(response.content)\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing LLM: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740c4a1e",
   "metadata": {},
   "source": [
    "## Document Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff0d027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e65d4690",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './data/cover_letter.pdf'\n",
    "loader = PyPDFLoader(file_path,mode='single')\n",
    "docs=loader.load()\n",
    "spliter = CharacterTextSplitter(chunk_size=1000 ,chunk_overlap=100,separator=\"\\n\")\n",
    "texts = spliter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "608e19a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class CharacterTextSplitter in module langchain_text_splitters.character:\n",
      "\n",
      "class CharacterTextSplitter(langchain_text_splitters.base.TextSplitter)\n",
      " |  CharacterTextSplitter(\n",
      " |      separator: 'str' = '\\n\\n',\n",
      " |      is_separator_regex: 'bool' = False,\n",
      " |      **kwargs: 'Any'\n",
      " |  ) -> 'None'\n",
      " |\n",
      " |  Splitting text that looks at characters.\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      CharacterTextSplitter\n",
      " |      langchain_text_splitters.base.TextSplitter\n",
      " |      langchain_core.documents.transformers.BaseDocumentTransformer\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(\n",
      " |      self,\n",
      " |      separator: 'str' = '\\n\\n',\n",
      " |      is_separator_regex: 'bool' = False,\n",
      " |      **kwargs: 'Any'\n",
      " |  ) -> 'None'\n",
      " |      Create a new TextSplitter.\n",
      " |\n",
      " |  split_text(self, text: 'str') -> 'list[str]'\n",
      " |      Split into chunks without re-inserting lookaround separators.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain_text_splitters.base.TextSplitter:\n",
      " |\n",
      " |  create_documents(\n",
      " |      self,\n",
      " |      texts: 'list[str]',\n",
      " |      metadatas: 'Optional[list[dict[Any, Any]]]' = None\n",
      " |  ) -> 'list[Document]'\n",
      " |      Create documents from a list of texts.\n",
      " |\n",
      " |  split_documents(self, documents: 'Iterable[Document]') -> 'list[Document]'\n",
      " |      Split documents.\n",
      " |\n",
      " |  transform_documents(self, documents: 'Sequence[Document]', **kwargs: 'Any') -> 'Sequence[Document]'\n",
      " |      Transform sequence of documents by splitting them.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from langchain_text_splitters.base.TextSplitter:\n",
      " |\n",
      " |  from_huggingface_tokenizer(tokenizer: 'Any', **kwargs: 'Any') -> 'TextSplitter'\n",
      " |      Text splitter that uses HuggingFace tokenizer to count length.\n",
      " |\n",
      " |  from_tiktoken_encoder(\n",
      " |      encoding_name: 'str' = 'gpt2',\n",
      " |      model_name: 'Optional[str]' = None,\n",
      " |      allowed_special: \"Union[Literal['all'], AbstractSet[str]]\" = set(),\n",
      " |      disallowed_special: \"Union[Literal['all'], Collection[str]]\" = 'all',\n",
      " |      **kwargs: 'Any'\n",
      " |  ) -> 'TS'\n",
      " |      Text splitter that uses tiktoken encoder to count length.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain_core.documents.transformers.BaseDocumentTransformer:\n",
      " |\n",
      " |  async atransform_documents(self, documents: 'Sequence[Document]', **kwargs: 'Any') -> 'Sequence[Document]'\n",
      " |      Asynchronously transform a list of documents.\n",
      " |\n",
      " |      Args:\n",
      " |          documents: A sequence of Documents to be transformed.\n",
      " |\n",
      " |      Returns:\n",
      " |          A sequence of transformed Documents.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from langchain_core.documents.transformers.BaseDocumentTransformer:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from abc.ABC:\n",
      " |\n",
      " |  __annotations__ = {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# texts\n",
    "help(CharacterTextSplitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "829f4a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a76d6c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33d7e604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0,separator=\"\\n\\n\")\n",
    "# texts = spliter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59a6bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0,is_separator_regex=True, separators=[\"\\n\\n\", \"\\n\", \" \", \"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72eaee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1426f488",
   "metadata": {},
   "source": [
    "## create vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e357a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding \n",
    "embeddings = GoogleGenerativeAIEmbeddings(model='models/gemini-embedding-001')\n",
    "vectorstore = Chroma.from_documents(texts,embedding=embeddings,collection_name=\"sample_collection\",persist_directory=\"./data/chroma_db2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffbc197",
   "metadata": {},
   "source": [
    "## Create retrival tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b9cedcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriver_tool = create_retriever_tool(\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    name=\"retriever_tool\",\n",
    "    description=\"\"\"This tool is used to retrieve relevant documents from the vector store based on the user's query.\n",
    "                   the informmation is about a person named 'Natdanai intraraksa' who is a software engineer and has worked at various companies including Invitrace and others.\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d2511d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = vectorstore.similarity_search(\"Which framework that I use to build the agent?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a78eca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='e46a77e1-0ddb-4169-92c8-0facb5e9d480', metadata={'total_pages': 2, 'producer': 'Skia/PDF m140 Google Docs Renderer', 'creationdate': '', 'source': './data/cover_letter.pdf', 'creator': 'PyPDF', 'title': 'Cover letter for apexanalytix'}, page_content='networks.\\n \\nWe\\n \\nfine-tuned\\n \\nlarge\\n \\nlanguage\\n \\nmodels\\n \\nusing\\n \\nthe\\n \\nUnsloth\\n \\nframework\\n \\nto\\n \\ngenerate\\n \\nstructured\\n \\nmedical\\n \\ndocumentation\\n \\nfrom\\n \\nunstructured\\n \\nnotes,\\n \\nsignificantly\\n \\nreducing\\n \\nthe\\n \\nworkload\\n \\nfor\\n \\nhealthcare\\n \\nprofessionals.\\n \\nThis\\n \\nsolution\\n \\nintegrated\\n \\nretrieval-augmented\\n \\ngeneration\\n \\n(RAG)\\n \\nto\\n \\nprovide\\n \\nreal-time,\\n \\ncontextually\\n \\nrelevant\\n \\ncontent\\n \\nand\\n \\nimprove\\n \\naccuracy.\\n \\n Previously  at  iBotnoi,  I  collaborated  with  Phramongkutklao  and  \\nSamutprakarn\\n \\nhospitals\\n \\nto\\n \\ndevelop\\n \\nAI-powered\\n \\nvirtual\\n \\nassistants\\n \\n(Nurse\\n \\nAI).\\n \\nThese\\n \\nassistants\\n \\nused\\n \\nfunction-calling\\n \\ncapabilities\\n \\nand\\n \\nintegrated\\n \\nwith\\n \\nhospital\\n \\nAPIs\\n \\nto\\n \\nsupport\\n \\nappointment\\n \\nmanagement\\n \\nand\\n \\npatient\\n \\ninteraction\\n \\nworkflows.\\n \\nMy\\n \\nwork\\n \\non\\n \\nthese\\n \\nprojects\\n \\nincluded\\n \\nimplementing\\n \\nmulti-agent\\n \\nsystems\\n \\nusing\\n \\nframeworks\\n \\nlike\\n \\nLangGraph\\n \\nand\\n \\nCrewAI\\n \\nto\\n \\nmanage\\n \\nautonomous\\n \\ntask\\n \\ndelegation\\n \\nand\\n \\nexecution'),\n",
       " Document(id='9b7ac4fd-1d7d-4546-b43b-8c4ab62292c5', metadata={'total_pages': 2, 'creator': 'PyPDF', 'producer': 'Skia/PDF m140 Google Docs Renderer', 'title': 'Cover letter for apexanalytix', 'creationdate': '', 'source': './data/cover_letter.pdf'}, page_content='like\\n \\nLangGraph\\n \\nand\\n \\nCrewAI\\n \\nto\\n \\nmanage\\n \\nautonomous\\n \\ntask\\n \\ndelegation\\n \\nand\\n \\nexecution\\n \\n \\n I  have  hands-on  experience  fine-tuning  LLMs  with  techniques  such  as  \\nLoRA,\\n \\nQLoRA,\\n \\nand\\n \\ninstruction\\n \\ntuning,\\n \\nand\\n \\nhave\\n \\nworked\\n \\nextensively\\n \\nwith\\n \\nLangChain,\\n \\nvector\\n \\ndatabases,\\n \\nand\\n \\nscalable\\n \\ndeployment\\n \\ntools\\n \\nsuch\\n \\nas\\n \\nDocker\\n \\nand\\n \\nKubernetes.\\n \\nMy\\n \\nbackground\\n \\nalso\\n \\nincludes\\n \\nbuilding\\n \\nMLOps\\n \\npipelines,\\n \\noptimizing\\n \\nmodel\\n \\nperformance,\\n \\nand\\n \\nensuring\\n \\ncompliance\\n \\nwith\\n \\nprivacy\\n \\nand\\n \\nsecurity\\n \\nstandards.\\n \\n I  would  welcome  the  opportunity  to  discuss  how  my  background  in  \\ndriving\\n \\nAI\\n \\nimplementation\\n \\nacross\\n \\ndiverse\\n \\nsectors\\n \\ncan\\n \\ncontribute\\n \\nto\\n \\nyour\\n \\nAI\\n \\nsolution.\\n \\nThank\\n \\nyou\\n \\nfor\\n \\nconsidering\\n \\nmy\\n \\napplication.\\n\\x0cSincerely,  \\nNatdanai  Intraraksa'),\n",
       " Document(id='0aad7154-1006-4d11-adef-af259e0d4d0d', metadata={'creator': 'PyPDF', 'source': './data/cover_letter.pdf', 'total_pages': 2, 'producer': 'Skia/PDF m140 Google Docs Renderer', 'creationdate': '', 'title': 'Cover letter for apexanalytix'}, page_content=\"Natdanai  Intraraksa  \\nAI  engineer  /  Data  Scientist   3217  w  Bertaue  Av.  Chicago,  IL  60618  \\n Intraraksa@gmail.com  \\n773-876-2897\\n \\n June  29,  2025  \\nHiring  manager  \\nApexanalytix  .Inc  \\n I  am  writing  to  express  my  strong  interest  in  the  AI  Engineer  \\nposition.\\n \\nWith\\n \\nover\\n \\nfive\\n \\nyears\\n \\nof\\n \\nexperience\\n \\nin\\n \\nAI\\n \\nengineering\\n \\nand\\n \\ndata\\n \\nscience,\\n \\nalong\\n \\nwith\\n \\na\\n \\ndecade\\n \\nof\\n \\nexperience\\n \\nas\\n \\na\\n \\nmanufacturing\\n \\nengineer,\\n \\nI\\n \\nbring\\n \\na\\n \\nwell-rounded\\n \\nbackground\\n \\nin\\n \\nboth\\n \\npractical\\n \\nengineering\\n \\nand\\n \\ncutting-edge\\n \\nAI\\n \\nsolution\\n \\ndevelopment.\\n \\nI\\n \\nrecently\\n \\nrelocated\\n \\nfrom\\n \\nThailand\\n \\nand\\n \\nam\\n \\neager\\n \\nto\\n \\ncontribute\\n \\nmy\\n \\nexpertise\\n \\nto\\n \\nyour\\n \\nteam.\\n \\n In  my  most  recent  role  at  Invitrace,  I  led  a  team  in  the  successful  \\ndeployment\\n \\nof\\n \\na\\n \\ngenerative\\n \\nAI\\n \\nsolution\\n \\nfor\\n \\none\\n \\nof\\n \\nThailand's\\n \\nlargest\\n \\nhospital\\n \\nnetworks.\\n \\nWe\\n \\nfine-tuned\\n \\nlarge\\n \\nlanguage\\n \\nmodels\\n \\nusing\\n \\nthe\\n \\nUnsloth\\n \\nframework\")]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6dc6d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def retrieve_documents(query: str):\n",
    "    \"\"\"Tools for retrive information that relevant to my information of the users\"\"\"\n",
    "    results = vectorstore.similarity_search(query)\n",
    "    return results\n",
    "\n",
    "@tool\n",
    "def multiply_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b + 9\n",
    "\n",
    "tools = [retrieve_documents, multiply_numbers]\n",
    "\n",
    "def query_vectorstore(state:MessagesState):\n",
    "    prompt = ''' you are AI agent that answer the question by using tools'''\n",
    "    agent = create_react_agent(llm, tools=[retriver_tool], prompt=prompt)\n",
    "    result = agent.invoke({'messages':state['messages']})\n",
    "    return {'messages': result['messages']}\n",
    "\n",
    "def Agent(state:MessagesState):\n",
    "    llm_with_tools = llm.bind_tools([retriver_tool])\n",
    "    response = llm_with_tools.invoke(state['messages'])\n",
    "    return response\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "124e6261",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = MessagesState()\n",
    "state['messages'] = \"What does Natdanai do at Samutprakarn hospitals?\"\n",
    "\n",
    "r = Agent(state)\n",
    "r2 = query_vectorstore(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bc90d168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'retriever_tool', 'arguments': '{\"query\": \"What does Natdanai do at Samutprakarn hospitals?\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--c7c51ca5-473b-4f18-9807-34dd6871c67c-0', tool_calls=[{'name': 'retriever_tool', 'args': {'query': 'What does Natdanai do at Samutprakarn hospitals?'}, 'id': 'db8b8d01-da13-4537-96c0-c77e8a396e9e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 110, 'output_tokens': 95, 'total_tokens': 205, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 66}})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "46c50e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What does Natdanai do at Samutprakarn hospitals?', additional_kwargs={}, response_metadata={}, id='5d40f843-e043-403e-a991-d4cb59267349'),\n",
       " AIMessage(content='', additional_kwargs={'function_call': {'name': 'retriever_tool', 'arguments': '{\"query\": \"What does Natdanai do at Samutprakarn hospitals?\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--7f708c71-b12d-4952-a815-bc79707fae5f-0', tool_calls=[{'name': 'retriever_tool', 'args': {'query': 'What does Natdanai do at Samutprakarn hospitals?'}, 'id': '5ec96b22-7d58-44c6-a89d-5ce2d5d67468', 'type': 'tool_call'}], usage_metadata={'input_tokens': 121, 'output_tokens': 186, 'total_tokens': 307, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 157}}),\n",
       " ToolMessage(content=\"networks.\\n \\nWe\\n \\nfine-tuned\\n \\nlarge\\n \\nlanguage\\n \\nmodels\\n \\nusing\\n \\nthe\\n \\nUnsloth\\n \\nframework\\n \\nto\\n \\ngenerate\\n \\nstructured\\n \\nmedical\\n \\ndocumentation\\n \\nfrom\\n \\nunstructured\\n \\nnotes,\\n \\nsignificantly\\n \\nreducing\\n \\nthe\\n \\nworkload\\n \\nfor\\n \\nhealthcare\\n \\nprofessionals.\\n \\nThis\\n \\nsolution\\n \\nintegrated\\n \\nretrieval-augmented\\n \\ngeneration\\n \\n(RAG)\\n \\nto\\n \\nprovide\\n \\nreal-time,\\n \\ncontextually\\n \\nrelevant\\n \\ncontent\\n \\nand\\n \\nimprove\\n \\naccuracy.\\n \\n Previously  at  iBotnoi,  I  collaborated  with  Phramongkutklao  and  \\nSamutprakarn\\n \\nhospitals\\n \\nto\\n \\ndevelop\\n \\nAI-powered\\n \\nvirtual\\n \\nassistants\\n \\n(Nurse\\n \\nAI).\\n \\nThese\\n \\nassistants\\n \\nused\\n \\nfunction-calling\\n \\ncapabilities\\n \\nand\\n \\nintegrated\\n \\nwith\\n \\nhospital\\n \\nAPIs\\n \\nto\\n \\nsupport\\n \\nappointment\\n \\nmanagement\\n \\nand\\n \\npatient\\n \\ninteraction\\n \\nworkflows.\\n \\nMy\\n \\nwork\\n \\non\\n \\nthese\\n \\nprojects\\n \\nincluded\\n \\nimplementing\\n \\nmulti-agent\\n \\nsystems\\n \\nusing\\n \\nframeworks\\n \\nlike\\n \\nLangGraph\\n \\nand\\n \\nCrewAI\\n \\nto\\n \\nmanage\\n \\nautonomous\\n \\ntask\\n \\ndelegation\\n \\nand\\n \\nexecution\\n\\nNatdanai  Intraraksa  \\nAI  engineer  /  Data  Scientist   3217  w  Bertaue  Av.  Chicago,  IL  60618  \\n Intraraksa@gmail.com  \\n773-876-2897\\n \\n June  29,  2025  \\nHiring  manager  \\nApexanalytix  .Inc  \\n I  am  writing  to  express  my  strong  interest  in  the  AI  Engineer  \\nposition.\\n \\nWith\\n \\nover\\n \\nfive\\n \\nyears\\n \\nof\\n \\nexperience\\n \\nin\\n \\nAI\\n \\nengineering\\n \\nand\\n \\ndata\\n \\nscience,\\n \\nalong\\n \\nwith\\n \\na\\n \\ndecade\\n \\nof\\n \\nexperience\\n \\nas\\n \\na\\n \\nmanufacturing\\n \\nengineer,\\n \\nI\\n \\nbring\\n \\na\\n \\nwell-rounded\\n \\nbackground\\n \\nin\\n \\nboth\\n \\npractical\\n \\nengineering\\n \\nand\\n \\ncutting-edge\\n \\nAI\\n \\nsolution\\n \\ndevelopment.\\n \\nI\\n \\nrecently\\n \\nrelocated\\n \\nfrom\\n \\nThailand\\n \\nand\\n \\nam\\n \\neager\\n \\nto\\n \\ncontribute\\n \\nmy\\n \\nexpertise\\n \\nto\\n \\nyour\\n \\nteam.\\n \\n In  my  most  recent  role  at  Invitrace,  I  led  a  team  in  the  successful  \\ndeployment\\n \\nof\\n \\na\\n \\ngenerative\\n \\nAI\\n \\nsolution\\n \\nfor\\n \\none\\n \\nof\\n \\nThailand's\\n \\nlargest\\n \\nhospital\\n \\nnetworks.\\n \\nWe\\n \\nfine-tuned\\n \\nlarge\\n \\nlanguage\\n \\nmodels\\n \\nusing\\n \\nthe\\n \\nUnsloth\\n \\nframework\\n\\nlike\\n \\nLangGraph\\n \\nand\\n \\nCrewAI\\n \\nto\\n \\nmanage\\n \\nautonomous\\n \\ntask\\n \\ndelegation\\n \\nand\\n \\nexecution\\n \\n \\n I  have  hands-on  experience  fine-tuning  LLMs  with  techniques  such  as  \\nLoRA,\\n \\nQLoRA,\\n \\nand\\n \\ninstruction\\n \\ntuning,\\n \\nand\\n \\nhave\\n \\nworked\\n \\nextensively\\n \\nwith\\n \\nLangChain,\\n \\nvector\\n \\ndatabases,\\n \\nand\\n \\nscalable\\n \\ndeployment\\n \\ntools\\n \\nsuch\\n \\nas\\n \\nDocker\\n \\nand\\n \\nKubernetes.\\n \\nMy\\n \\nbackground\\n \\nalso\\n \\nincludes\\n \\nbuilding\\n \\nMLOps\\n \\npipelines,\\n \\noptimizing\\n \\nmodel\\n \\nperformance,\\n \\nand\\n \\nensuring\\n \\ncompliance\\n \\nwith\\n \\nprivacy\\n \\nand\\n \\nsecurity\\n \\nstandards.\\n \\n I  would  welcome  the  opportunity  to  discuss  how  my  background  in  \\ndriving\\n \\nAI\\n \\nimplementation\\n \\nacross\\n \\ndiverse\\n \\nsectors\\n \\ncan\\n \\ncontribute\\n \\nto\\n \\nyour\\n \\nAI\\n \\nsolution.\\n \\nThank\\n \\nyou\\n \\nfor\\n \\nconsidering\\n \\nmy\\n \\napplication.\\n\\x0cSincerely,  \\nNatdanai  Intraraksa\", name='retriever_tool', id='02de5ea1-0e45-4188-9fb9-e15d1b1d9ff1', tool_call_id='5ec96b22-7d58-44c6-a89d-5ce2d5d67468'),\n",
       " AIMessage(content='Natdanai collaborated with Samutprakarn hospitals to develop AI-powered virtual assistants called \"Nurse AI.\" These assistants utilized function-calling capabilities and integrated with hospital APIs to manage appointment scheduling and patient interactions. His work also involved implementing multi-agent systems using frameworks like LangGraph and CrewAI for autonomous task delegation and execution.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--0cab06e3-2c2b-473f-b02c-906e2e2916b7-0', usage_metadata={'input_tokens': 1626, 'output_tokens': 173, 'total_tokens': 1799, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 106}})]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2['messages']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3b68f9",
   "metadata": {},
   "source": [
    "## Grade Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1be6de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Grade documents using a binary score for relevance check.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Relevance score: 'yes' if relevant, or 'no' if not relevant\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cad89831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'generate_answer'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grade_documents(state:MessagesState) -> Literal[\"generate_answer\", \"rewrite_question\"]:\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an expert at determining the relevance of documents to a given question.\"),\n",
    "        (\"user\", \"\"\"Given the question and the retrieved documents, determine if the documents are relevant to answer the question.\n",
    "                    Respond with 'yes' if relevant, or 'no' if not relevant.\n",
    "                    Question: {question}\n",
    "                    Documents: {documents}\"\"\")\n",
    "    ])\n",
    "    # Extract the question and documents from the state\n",
    "    question = state['messages'] if isinstance(state['messages'], str) else state['messages'][0].content\n",
    "    documents = state['messages'][-1].content if hasattr(state['messages'][-1], 'content') else str(state['messages'])\n",
    "\n",
    "    # Format the prompt first\n",
    "    formatted_prompt = prompt.format_messages(\n",
    "        question=question,\n",
    "        documents=documents\n",
    "    )\n",
    "    \n",
    "    llm_with_structured_output = llm.with_structured_output(GradeDocuments)\n",
    "    response = llm_with_structured_output.invoke(formatted_prompt)\n",
    "    if response.binary_score == \"yes\":\n",
    "        return \"generate_answer\"\n",
    "    else:\n",
    "        return \"rewrite_question\"\n",
    "    \n",
    "   \n",
    "\n",
    "grade_documents(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1704ba78",
   "metadata": {},
   "source": [
    "## Rewrite node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37ffc879",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rewrite_question(state: MessagesState):\n",
    "    \"\"\"Rewrite the original user question.\"\"\"\n",
    "\n",
    "\n",
    "    REWRITE_PROMPT = (\n",
    "    \"Look at the input and try to reason about the underlying semantic intent / meaning.\\n\"\n",
    "    \"Here is the initial question:\"\n",
    "    \"\\n ------- \\n\"\n",
    "    \"{question}\"\n",
    "    \"\\n ------- \\n\"\n",
    "    \"Formulate an improved question:\"\n",
    "    )\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    prompt = REWRITE_PROMPT.format(question=question)\n",
    "    response = llm.invoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "    return {\"messages\": [{\"role\": \"user\", \"content\": response.content}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7ed01670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state: MessagesState):\n",
    "    \"\"\"Generate an answer.\"\"\"\n",
    "\n",
    "    GENERATE_PROMPT = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer the question. \"\n",
    "    \"If you don't know the answer, just say that you don't know. \"\n",
    "    \"Use three sentences maximum and keep the answer concise.\\n\"\n",
    "    \"Question: {question} \\n\"\n",
    "    \"Context: {context}\"\n",
    "    )\n",
    "\n",
    "    question = state[\"messages\"][0].content\n",
    "    context = state[\"messages\"][-1].content\n",
    "    prompt = GENERATE_PROMPT.format(question=question, context=context)\n",
    "    response = llm.invoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd08241e",
   "metadata": {},
   "source": [
    "## Construct Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6d5ac5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the workflow\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"agent\",query_vectorstore)\n",
    "# workflow.add_node(\"grade_documents\", grade_documents)\n",
    "workflow.add_node(\"rewrite_question\", rewrite_question)\n",
    "workflow.add_node(\"generate_answer\", generate_answer)\n",
    "workflow.add_edge(START,\"agent\")\n",
    "# workflow.add_edge(\"agent\", \"grade_documents\")\n",
    "workflow.add_conditional_edges('agent',\n",
    "        grade_documents, {\n",
    "        \"generate_answer\": \"generate_answer\",\n",
    "        \"rewrite_question\": \"rewrite_question\",})\n",
    "workflow.add_edge(\"rewrite_question\", \"agent\")\n",
    "workflow.add_edge(\"generate_answer\", END)\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "59757f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = graph.invoke({'messages': \"What does he do at previous company?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d5396b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What does he do at previous company?', additional_kwargs={}, response_metadata={}, id='13b2bfbe-91f2-498c-b987-c8b7b92eebd8'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'retriever_tool', 'arguments': '{\"query\": \"Natdanai Intraraksa\\'s previous company roles and responsibilities\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--2778207a-ecfe-4efe-b8f4-1181fbd67e47-0', tool_calls=[{'name': 'retriever_tool', 'args': {'query': \"Natdanai Intraraksa's previous company roles and responsibilities\"}, 'id': '02a8e811-8f65-4c5b-9731-22305697fb96', 'type': 'tool_call'}], usage_metadata={'input_tokens': 115, 'output_tokens': 124, 'total_tokens': 239, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 94}}),\n",
       "  ToolMessage(content=\"like\\n \\nLangGraph\\n \\nand\\n \\nCrewAI\\n \\nto\\n \\nmanage\\n \\nautonomous\\n \\ntask\\n \\ndelegation\\n \\nand\\n \\nexecution\\n \\n \\n I  have  hands-on  experience  fine-tuning  LLMs  with  techniques  such  as  \\nLoRA,\\n \\nQLoRA,\\n \\nand\\n \\ninstruction\\n \\ntuning,\\n \\nand\\n \\nhave\\n \\nworked\\n \\nextensively\\n \\nwith\\n \\nLangChain,\\n \\nvector\\n \\ndatabases,\\n \\nand\\n \\nscalable\\n \\ndeployment\\n \\ntools\\n \\nsuch\\n \\nas\\n \\nDocker\\n \\nand\\n \\nKubernetes.\\n \\nMy\\n \\nbackground\\n \\nalso\\n \\nincludes\\n \\nbuilding\\n \\nMLOps\\n \\npipelines,\\n \\noptimizing\\n \\nmodel\\n \\nperformance,\\n \\nand\\n \\nensuring\\n \\ncompliance\\n \\nwith\\n \\nprivacy\\n \\nand\\n \\nsecurity\\n \\nstandards.\\n \\n I  would  welcome  the  opportunity  to  discuss  how  my  background  in  \\ndriving\\n \\nAI\\n \\nimplementation\\n \\nacross\\n \\ndiverse\\n \\nsectors\\n \\ncan\\n \\ncontribute\\n \\nto\\n \\nyour\\n \\nAI\\n \\nsolution.\\n \\nThank\\n \\nyou\\n \\nfor\\n \\nconsidering\\n \\nmy\\n \\napplication.\\n\\x0cSincerely,  \\nNatdanai  Intraraksa\\n\\nNatdanai  Intraraksa  \\nAI  engineer  /  Data  Scientist   3217  w  Bertaue  Av.  Chicago,  IL  60618  \\n Intraraksa@gmail.com  \\n773-876-2897\\n \\n June  29,  2025  \\nHiring  manager  \\nApexanalytix  .Inc  \\n I  am  writing  to  express  my  strong  interest  in  the  AI  Engineer  \\nposition.\\n \\nWith\\n \\nover\\n \\nfive\\n \\nyears\\n \\nof\\n \\nexperience\\n \\nin\\n \\nAI\\n \\nengineering\\n \\nand\\n \\ndata\\n \\nscience,\\n \\nalong\\n \\nwith\\n \\na\\n \\ndecade\\n \\nof\\n \\nexperience\\n \\nas\\n \\na\\n \\nmanufacturing\\n \\nengineer,\\n \\nI\\n \\nbring\\n \\na\\n \\nwell-rounded\\n \\nbackground\\n \\nin\\n \\nboth\\n \\npractical\\n \\nengineering\\n \\nand\\n \\ncutting-edge\\n \\nAI\\n \\nsolution\\n \\ndevelopment.\\n \\nI\\n \\nrecently\\n \\nrelocated\\n \\nfrom\\n \\nThailand\\n \\nand\\n \\nam\\n \\neager\\n \\nto\\n \\ncontribute\\n \\nmy\\n \\nexpertise\\n \\nto\\n \\nyour\\n \\nteam.\\n \\n In  my  most  recent  role  at  Invitrace,  I  led  a  team  in  the  successful  \\ndeployment\\n \\nof\\n \\na\\n \\ngenerative\\n \\nAI\\n \\nsolution\\n \\nfor\\n \\none\\n \\nof\\n \\nThailand's\\n \\nlargest\\n \\nhospital\\n \\nnetworks.\\n \\nWe\\n \\nfine-tuned\\n \\nlarge\\n \\nlanguage\\n \\nmodels\\n \\nusing\\n \\nthe\\n \\nUnsloth\\n \\nframework\\n\\nnetworks.\\n \\nWe\\n \\nfine-tuned\\n \\nlarge\\n \\nlanguage\\n \\nmodels\\n \\nusing\\n \\nthe\\n \\nUnsloth\\n \\nframework\\n \\nto\\n \\ngenerate\\n \\nstructured\\n \\nmedical\\n \\ndocumentation\\n \\nfrom\\n \\nunstructured\\n \\nnotes,\\n \\nsignificantly\\n \\nreducing\\n \\nthe\\n \\nworkload\\n \\nfor\\n \\nhealthcare\\n \\nprofessionals.\\n \\nThis\\n \\nsolution\\n \\nintegrated\\n \\nretrieval-augmented\\n \\ngeneration\\n \\n(RAG)\\n \\nto\\n \\nprovide\\n \\nreal-time,\\n \\ncontextually\\n \\nrelevant\\n \\ncontent\\n \\nand\\n \\nimprove\\n \\naccuracy.\\n \\n Previously  at  iBotnoi,  I  collaborated  with  Phramongkutklao  and  \\nSamutprakarn\\n \\nhospitals\\n \\nto\\n \\ndevelop\\n \\nAI-powered\\n \\nvirtual\\n \\nassistants\\n \\n(Nurse\\n \\nAI).\\n \\nThese\\n \\nassistants\\n \\nused\\n \\nfunction-calling\\n \\ncapabilities\\n \\nand\\n \\nintegrated\\n \\nwith\\n \\nhospital\\n \\nAPIs\\n \\nto\\n \\nsupport\\n \\nappointment\\n \\nmanagement\\n \\nand\\n \\npatient\\n \\ninteraction\\n \\nworkflows.\\n \\nMy\\n \\nwork\\n \\non\\n \\nthese\\n \\nprojects\\n \\nincluded\\n \\nimplementing\\n \\nmulti-agent\\n \\nsystems\\n \\nusing\\n \\nframeworks\\n \\nlike\\n \\nLangGraph\\n \\nand\\n \\nCrewAI\\n \\nto\\n \\nmanage\\n \\nautonomous\\n \\ntask\\n \\ndelegation\\n \\nand\\n \\nexecution\", name='retriever_tool', id='bad47fa5-5bd9-4c7b-a6db-4494d1527c68', tool_call_id='02a8e811-8f65-4c5b-9731-22305697fb96'),\n",
       "  AIMessage(content='At Invitrace, Natdanai Intraraksa led a team in deploying a generative AI solution for a large hospital network in Thailand. This involved fine-tuning large language models using the Unsloth framework to generate structured medical documentation from unstructured notes, and integrating retrieval-augmented generation (RAG) for real-time, contextually relevant content.\\n\\nPreviously, at iBotnoi, he collaborated with Phramongkutklao and Samutprakarn hospitals to develop AI-powered virtual assistants (Nurse AI). These assistants utilized function-calling capabilities and integrated with hospital APIs to support appointment management and patient interaction workflows. His work on these projects included implementing multi-agent systems using frameworks like LangGraph and CrewAI for autonomous task delegation and execution.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--e4b89c52-7cec-4121-8209-c21ef14ceca4-0', usage_metadata={'input_tokens': 1621, 'output_tokens': 211, 'total_tokens': 1832, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 58}}),\n",
       "  AIMessage(content='At his previous company, iBotnoi, Natdanai Intraraksa developed AI-powered virtual assistants (Nurse AI) in collaboration with Phramongkutklao and Samutprakarn hospitals. These assistants supported appointment management and patient interaction workflows by utilizing function-calling capabilities and integrating with hospital APIs. He also implemented multi-agent systems using frameworks like LangGraph and CrewAI for autonomous task delegation.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--13bed351-1558-4bae-9591-476778dfd7ca-0', usage_metadata={'input_tokens': 220, 'output_tokens': 269, 'total_tokens': 489, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 185}})]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bd50a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agentic-RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
